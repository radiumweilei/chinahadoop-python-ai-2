{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文章1: [tensorflow-梯度下降,有这一篇就足够了](https://segmentfault.com/a/1190000011994447)\n",
    "## 参考文章2: [梯度下降（Gradient Descent）小结](https://www.cnblogs.com/pinard/p/5970503.html)\n",
    "## 参考文章3: [深度解读最流行的优化算法：梯度下降](https://www.cnblogs.com/shixiangwan/p/7532858.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 单变量函数梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单变量3阶函数\n",
    "def f(x):\n",
    "    return x**3 + 2 * x - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(x):\n",
    "    return (f(x) - 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x):\n",
    "    delta = 0.00000001\n",
    "    derivative = (error(x + delta) - error(x)) / delta\n",
    "    rate = 0.01\n",
    "    return x - rate * derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = 0.8\n",
    "for i in range(50):\n",
    "    x = gradient_descent(x)\n",
    "    print('x = {:6f}, f(x) = {:6f}'.format(x, f(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 双变量函数梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 双变量函数\n",
    "def f(x):\n",
    "    return x[0] + 2 * x[1] + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(x):\n",
    "    return (f(x) - 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x):\n",
    "    delta = 0.00000001\n",
    "    derivative_x0 = (error([x[0] + delta, x[1]]) - error([x[0], x[1]])) / delta\n",
    "    derivative_x1 = (error([x[0], x[1] + delta]) - error([x[0], x[1]])) / delta\n",
    "    rate = 0.02\n",
    "    x[0] = x[0] - rate * derivative_x0\n",
    "    x[1] = x[1] - rate * derivative_x1\n",
    "    return [x[0], x[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [-0.5, -1.0]\n",
    "for i in range(100):\n",
    "    x = gradient_descent(x)\n",
    "    print('x = {:6f},{:6f}, f(x) = {:6f}'.format(x[0],x[1],f(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}